import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import joblib
import os

# 1ï¸âƒ£ Load dá»¯ liá»‡u
df = pd.read_csv("D:/Pycharm/weather-new/data/Processed/Duration/storm_duration_dataset.csv", parse_dates=["Datetime"])

# 2ï¸âƒ£ MÃ£ hÃ³a cá»™t 'Season' thÃ nh sá»‘
season_mapping = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Autumn': 3}
df['Season'] = df['Season'].map(season_mapping)


# 3ï¸âƒ£ Cáº­p nháº­t Ä‘áº·c trÆ°ng vÃ  nhÃ£n
# Náº¿u Season Ä‘Ã£ cÃ³ sáºµn trong dá»¯ liá»‡u, ta chá»‰ cáº§n thÃªm vÃ o danh sÃ¡ch features
features = [
    'Rain', 'Temp', 'WindSpeed', 'Pressure',
    'Humidity', 'CloudCover', 'WindDirection',
    'Month', 'Season'  # Äáº£m báº£o Season Ä‘Ã£ cÃ³ trong dá»¯ liá»‡u
]
target = 'duration_in_storm'
X = df[features]
y = df[target]

# 4ï¸âƒ£ Tiá»n xá»­ lÃ½
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=features)

# 5ï¸âƒ£ Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# 6ï¸âƒ£ Huáº¥n luyá»‡n Random Forest (tá»‘i Æ°u)
model = RandomForestRegressor(
    n_estimators=400,
    max_depth=16,
    min_samples_split=5,
    min_samples_leaf=2,
    max_features='sqrt',
    bootstrap=True,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train, y_train)

# 7ï¸âƒ£ ÄÃ¡nh giÃ¡
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("ğŸ¯ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Random Forest (Ä‘Ã£ chá»‰nh):")
print(f"â–ªï¸ MAE: {mae:.2f}")
print(f"â–ªï¸ MSE: {mse:.2f}")
print(f"â–ªï¸ RÂ²: {r2:.2f}")

# 8ï¸âƒ£ LÆ°u model vÃ  scaler
os.makedirs("model_use", exist_ok=True)
joblib.dump(model, "model_use/duration_rf_model.pkl")
joblib.dump(scaler, "model_use/duration_scaler.pkl")
print("âœ… ÄÃ£ lÆ°u model vÃ  scaler vÃ o thÆ° má»¥c model_use/")

# 9ï¸âƒ£ Trá»±c quan hÃ³a káº¿t quáº£

# 9.1 Dá»± Ä‘oÃ¡n vs Thá»±c táº¿
plt.figure(figsize=(6, 5))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel("Thá»±c táº¿ (duration)")
plt.ylabel("Dá»± Ä‘oÃ¡n (duration)")
plt.title("Random Forest: Dá»± Ä‘oÃ¡n vs Thá»±c táº¿")
plt.tight_layout()
plt.show()

# 9.2 PhÃ¢n phá»‘i lá»—i
errors = y_test - y_pred
plt.figure(figsize=(6, 4))
sns.histplot(errors, bins=40, kde=True, color="orange")
plt.title("PhÃ¢n phá»‘i lá»—i dá»± Ä‘oÃ¡n (Random Forest)")
plt.xlabel("Lá»—i (giá»)")
plt.tight_layout()
plt.show()

# 9.3 Feature importance
plt.figure(figsize=(8, 5))
sns.barplot(x=model.feature_importances_, y=features, color="teal")
plt.title("Äá»™ quan trá»ng cá»§a cÃ¡c Ä‘áº·c trÆ°ng (Random Forest)")
plt.tight_layout()
plt.show()
