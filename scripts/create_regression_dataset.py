import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
import joblib
import os

# âœ… 1. Load dá»¯ liá»‡u
df = pd.read_csv("D:/Pycharm/weather-new/data/Processed/Regression/storm_regression_dataset.csv")

# âœ… 2. Giá»¯ láº¡i nhá»¯ng dÃ²ng cÃ³ max_wind > 0 (Ä‘iá»ƒm cÃ³ bÃ£o)
df = df[df["max_wind"] > 0]

# âœ… 3. Äáº·c trÆ°ng vÃ  nhÃ£n
features = ['Rain', 'Temp', 'WindSpeed', 'Pressure', 'Humidity', 'CloudCover', 'WindDirection']
target = "max_wind"
X = df[features]
y = df[target]

# âœ… 4. Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# âœ… 5. Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# âœ… 6. Huáº¥n luyá»‡n XGBoost Regressor
model = XGBRegressor(
    objective='reg:squarederror',
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_train, y_train)

# âœ… 7. ÄÃ¡nh giÃ¡
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("ğŸ“ˆ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh XGBoost:")
print(f"â–ªï¸ MAE: {mae:.2f}")
print(f"â–ªï¸ MSE: {mse:.2f}")
print(f"â–ªï¸ RÂ²: {r2:.2f}")

# âœ… 8. LÆ°u model & scaler
os.makedirs("model_use", exist_ok=True)
joblib.dump(model, "model_use/regression_xgboost_maxwind.pkl")
joblib.dump(scaler, "model_use/regression_scaler.pkl")
print("âœ… ÄÃ£ lÆ°u model vÃ  scaler.")

# âœ… 9. Trá»±c quan hÃ³a
# 9.1 Thá»±c táº¿ vs Dá»± Ä‘oÃ¡n
plt.figure(figsize=(6, 5))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel("Thá»±c táº¿ (max_wind)")
plt.ylabel("Dá»± Ä‘oÃ¡n (max_wind)")
plt.title("ğŸ¯ XGBoost: Dá»± Ä‘oÃ¡n vs Thá»±c táº¿")
plt.tight_layout()
plt.show()

# 9.2 PhÃ¢n phá»‘i lá»—i
errors = y_test - y_pred
plt.figure(figsize=(6, 4))
sns.histplot(errors, bins=50, kde=True, color="tomato")
plt.title("PhÃ¢n phá»‘i lá»—i dá»± Ä‘oÃ¡n (XGBoost)")
plt.xlabel("Lá»—i")
plt.tight_layout()
plt.show()

# 9.3 Feature Importance
plt.figure(figsize=(8, 5))
sns.barplot(x=model.feature_importances_, y=features, color="teal")
plt.title("ğŸ“Š Feature Importance (XGBoost)")
plt.tight_layout()
plt.show()
